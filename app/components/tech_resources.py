"""
Tech Resources Library Component
Browse engineering blogs, papers, and learning resources from major tech companies
"""
import streamlit as st
import json
from pathlib import Path
from typing import Dict, List


def load_tech_resources() -> Dict:
    """Load tech resources from JSON file."""
    resources_file = Path(__file__).parent.parent.parent / "data" / "tech_resources.json"
    
    if resources_file.exists():
        with open(resources_file, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def render_tech_resources():
    """Render the tech resources library page."""
    
    st.markdown("## ğŸ“– æŠ€æœ¯èµ„æºåº“")
    st.markdown("*å„å¤§å…¬å¸æŠ€æœ¯åšå®¢ã€å¿…è¯»è®ºæ–‡ã€å­¦ä¹ è¯¾ç¨‹*")
    
    # Load data
    data = load_tech_resources()
    companies = data.get("companies", {})
    learning = data.get("learning_resources", {})
    topic_mapping = data.get("topic_mapping", {})
    
    if not companies:
        st.warning("èµ„æºåº“æš‚æ— æ•°æ®")
        return
    
    cutting_edge = data.get("cutting_edge_2024", {})
    
    # Tabs for different sections
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ”¥ æœ€æ–°è®ºæ–‡", "ğŸ¢ å…¬å¸è®ºæ–‡", "ğŸ“– å…¬å¸åšå®¢", "ğŸ“š ç»å…¸å¿…è¯»", "ğŸ“ å­¦ä¹ èµ„æº"])
    
    
    # ============ Tab 1: Latest Papers (Dynamic) ============
    with tab1:
        st.markdown("### ğŸ”¥ æœ€æ–° ML/AI è®ºæ–‡")
        st.markdown("*å®æ—¶ä» arXivã€Hugging Face è·å–æœ€æ–°ç ”ç©¶*")
        
        # Import papers fetcher
        try:
            import sys
            sys.path.insert(0, str(Path(__file__).parent.parent.parent))
            from data.papers_fetcher import papers_aggregator, get_hot_papers
            
            col1, col2 = st.columns([3, 1])
            with col2:
                if st.button("ğŸ”„ åˆ·æ–°è®ºæ–‡"):
                    with st.spinner("æ­£åœ¨è·å–æœ€æ–°è®ºæ–‡..."):
                        papers_aggregator.get_latest_papers(force_refresh=True)
                    st.success("å·²æ›´æ–°ï¼")
                    st.rerun()
            
            # Get latest papers
            with st.spinner("åŠ è½½æœ€æ–°è®ºæ–‡..."):
                latest_data = papers_aggregator.get_latest_papers()
            
            last_updated = latest_data.get("last_updated", "")
            if last_updated:
                st.caption(f"ğŸ“… ä¸Šæ¬¡æ›´æ–°: {last_updated[:19]}")
            
            # arXiv papers by category
            arxiv_data = latest_data.get("sources", {}).get("arxiv", {})
            
            for cat_name, papers in arxiv_data.items():
                if papers:
                    st.markdown(f"#### ğŸ“š {cat_name}")
                    
                    for paper in papers[:5]:  # Show top 5 per category
                        with st.expander(f"ğŸ“„ {paper.get('title', 'Untitled')[:80]}..."):
                            st.markdown(f"**ğŸ“… å‘å¸ƒæ—¥æœŸ**: {paper.get('published', 'N/A')}")
                            st.markdown(f"**ğŸ‘¥ ä½œè€…**: {', '.join(paper.get('authors', [])[:3])}")
                            st.markdown(f"ğŸ”— [arXiv é“¾æ¥]({paper.get('url', '#')})")
                            st.markdown("**æ‘˜è¦:**")
                            st.caption(paper.get("abstract", "")[:300] + "...")
                    
                    st.markdown("---")
            
            # Hugging Face Daily Papers
            hf_papers = latest_data.get("sources", {}).get("huggingface", [])
            if hf_papers:
                st.markdown("#### ğŸ¤— Hugging Face ä»Šæ—¥çƒ­é—¨")
                
                for paper in hf_papers[:10]:
                    with st.expander(f"ğŸ”¥ {paper.get('title', 'Untitled')[:80]}"):
                        st.markdown(f"ğŸ‘ **ç‚¹èµ**: {paper.get('upvotes', 0)}")
                        st.markdown(f"ğŸ”— [æŸ¥çœ‹è®ºæ–‡]({paper.get('url', '#')})")
                        if paper.get("abstract"):
                            st.caption(paper.get("abstract", "")[:200] + "...")
        
        except Exception as e:
            st.warning(f"æ— æ³•åŠ è½½æœ€æ–°è®ºæ–‡: {e}")
            st.info("æ˜¾ç¤ºç»å…¸è®ºæ–‡åˆ—è¡¨...")
            
            # Fallback to static cutting edge papers
            st.markdown("#### ğŸ¯ ç”Ÿæˆå¼æ¨è (Generative Recommendation)")
            for paper in cutting_edge.get("generative_recommendation", []):
                with st.expander(f"ğŸ“„ **{paper['title']}** ({paper.get('year', '')})"):
                    st.markdown(f"ğŸ”— [{paper['url']}]({paper['url']})")
                    st.markdown(f"ğŸ“ {paper.get('description', '')}")
    
    
    # ============ Tab 2: Company Papers ============
    with tab2:
        st.markdown("### ğŸ¢ å…¬å¸æœ€æ–°è®ºæ–‡")
        st.markdown("*è¿½è¸ªå„å¤§ç§‘æŠ€å…¬å¸çš„æœ€æ–°ç ”ç©¶æˆæœ*")
        
        try:
            from data.company_papers import company_papers, get_company_research_links
            
            # Get research links
            research_links = get_company_research_links()
            
            col1, col2 = st.columns([3, 1])
            with col2:
                if st.button("ğŸ”„ åˆ·æ–°å…¬å¸è®ºæ–‡"):
                    with st.spinner("æ­£åœ¨è·å–æœ€æ–°è®ºæ–‡..."):
                        company_papers.fetch_all_company_papers(force_refresh=True)
                    st.success("å·²æ›´æ–°ï¼")
                    st.rerun()
            
            # Company selector
            company_list = list(research_links.keys())
            selected = st.selectbox(
                "é€‰æ‹©å…¬å¸",
                ["å…¨éƒ¨"] + company_list,
                format_func=lambda x: "å…¨éƒ¨å…¬å¸" if x == "å…¨éƒ¨" else f"{research_links[x]['icon']} {research_links[x]['name']}"
            )
            
            st.markdown("---")
            
            if selected == "å…¨éƒ¨":
                display_links = research_links.items()
            else:
                display_links = [(selected, research_links[selected])]
            
            for company_id, info in display_links:
                st.markdown(f"### {info['icon']} {info['name']}")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.markdown(f"[ğŸ“ ç ”ç©¶åšå®¢]({info.get('research_blog', '#')})")
                with col2:
                    st.markdown(f"[ğŸ“š è®ºæ–‡åº“]({info.get('publications', '#')})")
                with col3:
                    st.markdown(f"[ğŸ” arXiv æœç´¢]({info.get('arxiv_search', '#')})")
                with col4:
                    st.markdown(f"[ğŸ’» GitHub]({info.get('github', '#')})")
                
                # Fetch recent papers from arXiv
                with st.spinner(f"è·å– {info['name']} æœ€æ–°è®ºæ–‡..."):
                    papers = company_papers.fetch_arxiv_by_affiliation(company_id, max_results=3)
                
                if papers:
                    for paper in papers:
                        with st.expander(f"ğŸ“„ {paper.get('title', 'Untitled')[:70]}..."):
                            st.markdown(f"**å‘å¸ƒæ—¥æœŸ**: {paper.get('published', 'N/A')}")
                            st.markdown(f"**ä½œè€…**: {', '.join(paper.get('authors', [])[:3])}")
                            st.markdown(f"ğŸ”— [arXiv é“¾æ¥]({paper.get('url', '#')})")
                            st.caption(paper.get("abstract", "")[:250] + "...")
                else:
                    st.caption("æš‚æ— æœ€æ–°è®ºæ–‡ï¼Œè¯·ç‚¹å‡»ä¸Šæ–¹é“¾æ¥è®¿é—®å®˜æ–¹é¡µé¢")
                
                st.markdown("---")
        
        except Exception as e:
            st.warning(f"åŠ è½½å…¬å¸è®ºæ–‡å¤±è´¥: {e}")
            st.info("è¯·è®¿é—®å„å…¬å¸å®˜æ–¹ç ”ç©¶é¡µé¢æŸ¥çœ‹æœ€æ–°è®ºæ–‡")
    
    # ============ Tab 3: Company Blogs ============
    with tab3:
        st.markdown("### ğŸ“– æŠ€æœ¯åšå®¢å¯¼èˆª")
        st.markdown("*ç‚¹å‡»é“¾æ¥ç›´æ¥è®¿é—®å„å…¬å¸å·¥ç¨‹åšå®¢*")
        
        # Company selection
        company_names = {k: v["name"] for k, v in companies.items()}
        selected_company = st.selectbox(
            "é€‰æ‹©å…¬å¸",
            ["å…¨éƒ¨"] + list(company_names.keys()),
            format_func=lambda x: "å…¨éƒ¨å…¬å¸" if x == "å…¨éƒ¨" else company_names.get(x, x)
        )
        
        st.markdown("---")
        
        if selected_company == "å…¨éƒ¨":
            display_companies = companies.items()
        else:
            display_companies = [(selected_company, companies[selected_company])]
        
        for company_id, company_data in display_companies:
            company_name = company_data.get("name", company_id)
            
            st.markdown(f"#### ğŸ¢ {company_name}")
            
            # Blog links
            for blog in company_data.get("blogs", []):
                topics_str = ", ".join([topic_mapping.get(t, t) for t in blog.get("topics", [])])
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**[{blog['name']}]({blog['url']})**")
                    st.caption(blog.get("description", ""))
                with col2:
                    st.caption(f"ğŸ“Œ {topics_str}")
            
            st.markdown("---")
    
    # ============ Tab 4: Must-Read Papers ============
    with tab4:
        st.markdown("### ğŸ“š å¿…è¯»è®ºæ–‡ & æ–‡ç« ")
        st.markdown("*MLE é¢è¯•é«˜é¢‘å¼•ç”¨çš„ç»å…¸è®ºæ–‡*")
        
        # Topic filter
        all_topics = set()
        for company_data in companies.values():
            for article in company_data.get("must_read_articles", []):
                all_topics.update(article.get("topics", []))
        
        col1, col2 = st.columns(2)
        with col1:
            selected_topic = st.selectbox(
                "æŒ‰ä¸»é¢˜ç­›é€‰",
                ["å…¨éƒ¨"] + sorted(list(all_topics)),
                format_func=lambda x: "å…¨éƒ¨ä¸»é¢˜" if x == "å…¨éƒ¨" else topic_mapping.get(x, x),
                key="paper_topic_filter"
            )
        with col2:
            selected_company_paper = st.selectbox(
                "æŒ‰å…¬å¸ç­›é€‰",
                ["å…¨éƒ¨"] + list(company_names.keys()),
                format_func=lambda x: "å…¨éƒ¨å…¬å¸" if x == "å…¨éƒ¨" else company_names.get(x, x),
                key="paper_company_filter"
            )
        
        st.markdown("---")
        
        # Collect and display papers
        all_papers = []
        for company_id, company_data in companies.items():
            for article in company_data.get("must_read_articles", []):
                article["company"] = company_data.get("name", company_id)
                article["company_id"] = company_id
                all_papers.append(article)
        
        # Sort by year descending
        all_papers = sorted(all_papers, key=lambda x: x.get("year", 0), reverse=True)
        
        # Apply filters
        if selected_topic != "å…¨éƒ¨":
            all_papers = [p for p in all_papers if selected_topic in p.get("topics", [])]
        if selected_company_paper != "å…¨éƒ¨":
            all_papers = [p for p in all_papers if p.get("company_id") == selected_company_paper]
        
        st.markdown(f"*å…± {len(all_papers)} ç¯‡å¿…è¯»æ–‡ç« *")
        
        for paper in all_papers:
            with st.expander(f"ğŸ“„ **{paper['title']}** ({paper.get('year', 'N/A')})"):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.markdown(f"ğŸ¢ **æ¥æº**: {paper.get('company', 'Unknown')}")
                    st.markdown(f"ğŸ”— **é“¾æ¥**: [{paper['url']}]({paper['url']})")
                    
                    topics_str = " ".join([f"`{topic_mapping.get(t, t)}`" for t in paper.get("topics", [])])
                    st.markdown(f"ğŸ·ï¸ **ä¸»é¢˜**: {topics_str}")
                
                with col2:
                    st.info(f"ğŸ’¡ {paper.get('relevance', '')}")
    
    # ============ Tab 5: Learning Resources ============
    with tab5:
        st.markdown("### ğŸ“ å­¦ä¹ èµ„æº")
        
        # Courses
        st.markdown("#### ğŸ“º æ¨èè¯¾ç¨‹")
        
        courses = learning.get("courses", [])
        for course in courses:
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                st.markdown(f"**[{course['name']}]({course['url']})**")
            with col2:
                st.caption(course.get("provider", ""))
            with col3:
                level_icons = {"beginner": "ğŸŸ¢", "intermediate": "ğŸŸ¡", "advanced": "ğŸ”´"}
                st.caption(f"{level_icons.get(course.get('level', ''), 'âšª')} {course.get('level', '').title()}")
        
        st.markdown("---")
        
        # Books
        st.markdown("#### ğŸ“š æ¨èä¹¦ç±")
        
        books = learning.get("books", [])
        for book in books:
            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**[{book['name']}]({book['url']})**")
                    st.caption(f"ä½œè€…: {book.get('author', 'Unknown')}")
                with col2:
                    st.info(f"ğŸ’¡ {book.get('relevance', '')}")
        
        st.markdown("---")
        
        # YouTube Channels
        st.markdown("#### ğŸ¬ YouTube é¢‘é“")
        
        channels = learning.get("youtube_channels", [])
        for channel in channels:
            col1, col2 = st.columns([2, 2])
            with col1:
                st.markdown(f"**[{channel['name']}]({channel['url']})**")
            with col2:
                st.caption(channel.get("relevance", ""))
        
        st.markdown("---")
        
        # Influential Personal Blogs
        st.markdown("#### âœï¸ å¤§ç‰›ä¸ªäººåšå®¢")
        
        blogs = data.get("influential_blogs", [])
        for blog in blogs:
            with st.expander(f"ğŸ“ **{blog['name']}** - {blog.get('author', '')}"):
                st.markdown(f"ğŸ”— [{blog['url']}]({blog['url']})")
                st.markdown(f"ğŸ¯ **ä¸“é•¿**: {blog.get('specialty', '')}")
                if blog.get("must_read"):
                    st.markdown("**å¿…è¯»æ–‡ç« :**")
                    for article in blog.get("must_read", []):
                        st.markdown(f"- {article}")
        
        st.markdown("---")
        
        # AI Conferences
        st.markdown("#### ğŸ“ é‡è¦ AI ä¼šè®®")
        
        conferences = data.get("ai_conferences", {})
        
        conf_col1, conf_col2 = st.columns(2)
        
        with conf_col1:
            st.markdown("**ğŸ† é¡¶çº§ä¼šè®®**")
            for conf in conferences.get("top_tier", []):
                st.markdown(f"- [{conf['name']}]({conf['url']}) ({conf.get('timing', '')})")
            
            st.markdown("**ğŸ“š NLP/LLM ä¼šè®®**")
            for conf in conferences.get("nlp_and_llm", []):
                st.markdown(f"- [{conf['name']}]({conf['url']}) ({conf.get('timing', '')})")
        
        with conf_col2:
            st.markdown("**ğŸ¯ åº”ç”¨ ML ä¼šè®®**")
            for conf in conferences.get("applied_ml", []):
                st.markdown(f"- [{conf['name']}]({conf['url']}) - {conf.get('relevance', '')}")
            
            st.markdown("**ğŸ‘ï¸ è®¡ç®—æœºè§†è§‰ä¼šè®®**")
            for conf in conferences.get("computer_vision", []):
                st.markdown(f"- [{conf['name']}]({conf['url']}) ({conf.get('timing', '')})")
    
    # ============ Quick Access Section ============
    st.markdown("---")
    st.markdown("### ğŸ’° èŒä¸šèµ„æº & è–ªé…¬æ•°æ®")
    
    career = data.get("career_resources", {})
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**ğŸ’µ è–ªé…¬æ•°æ®**")
        for site in career.get("salary_data", []):
            st.markdown(f"- [{site['name']}]({site['url']})")
            if site.get("description"):
                st.caption(site['description'])
    
    with col2:
        st.markdown("**ğŸ“Š å°±ä¸šå¸‚åœº**")
        for site in career.get("job_market", []):
            st.markdown(f"- [{site['name']}]({site['url']})")
            if site.get("description"):
                st.caption(site['description'])
    
    with col3:
        st.markdown("**ğŸ¢ å…¬å¸çº§åˆ«å¯¹ç…§**")
        levels = career.get("company_levels", {})
        for company, info in levels.items():
            st.markdown(f"**{company.upper()}**: {', '.join(info.get('levels', []))}")
            st.caption(f"[è–ªé…¬è¯¦æƒ…]({info.get('levels_fyi_url', '')})")
    
    st.markdown("---")
    st.markdown("### âš¡ å¿«é€Ÿè®¿é—®")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**ğŸ”¥ çƒ­é—¨åšå®¢**")
        st.markdown("""
        - [Lilian Weng](https://lilianweng.github.io/)
        - [Jay Alammar](https://jalammar.github.io/)
        - [Eugene Yan](https://eugeneyan.com/)
        """)
    
    with col2:
        st.markdown("**ğŸ“– 2024 å¿…è¯»è®ºæ–‡**")
        st.markdown("""
        - [Generative Rec Survey](https://arxiv.org/abs/2405.00318)
        - [RAG Survey](https://arxiv.org/abs/2312.10997)
        - [Llama 3](https://ai.meta.com/llama/)
        """)
    
    with col3:
        st.markdown("**ğŸ’° è–ªé…¬ & å°±ä¸š**")
        st.markdown("""
        - [levels.fyi](https://www.levels.fyi/)
        - [layoffs.fyi](https://layoffs.fyi/)
        - [Blind](https://www.teamblind.com/)
        """)

