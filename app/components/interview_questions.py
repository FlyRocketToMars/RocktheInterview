"""
Interview Questions Browser Component v2.0
Enhanced UI with professional MLE categorization and community answers
"""
import streamlit as st
import json
import hashlib
from pathlib import Path
from typing import Dict, List
from datetime import datetime
import sys

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


def load_question_answers(question_id: str) -> Dict:
    """Load community answers for a specific question."""
    answers_file = Path(__file__).parent.parent.parent / "data" / "question_answers.json"
    
    if answers_file.exists():
        try:
            with open(answers_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("questions", {}).get(question_id, {"answers": [], "stats": {}})
        except:
            pass
    return {"answers": [], "stats": {"views": 0, "total_answers": 0}}


def save_question_answer(question_id: str, answer: Dict):
    """Save a community answer for a question."""
    answers_file = Path(__file__).parent.parent.parent / "data" / "question_answers.json"
    
    # Load existing data
    data = {"questions": {}}
    if answers_file.exists():
        try:
            with open(answers_file, "r", encoding="utf-8") as f:
                data = json.load(f)
        except:
            pass
    
    # Initialize question if not exists
    if question_id not in data["questions"]:
        data["questions"][question_id] = {"answers": [], "stats": {"views": 0, "total_answers": 0}}
    
    # Add answer
    data["questions"][question_id]["answers"].append(answer)
    data["questions"][question_id]["stats"]["total_answers"] += 1
    
    # Save
    with open(answers_file, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)


def vote_answer(question_id: str, answer_id: str, is_upvote: bool = True):
    """Vote on an answer."""
    answers_file = Path(__file__).parent.parent.parent / "data" / "question_answers.json"
    
    if not answers_file.exists():
        return
    
    with open(answers_file, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    if question_id in data["questions"]:
        for ans in data["questions"][question_id]["answers"]:
            if ans.get("id") == answer_id:
                if is_upvote:
                    ans["upvotes"] = ans.get("upvotes", 0) + 1
                else:
                    ans["downvotes"] = ans.get("downvotes", 0) + 1
                break
        
        with open(answers_file, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)


def get_question_id(question: Dict) -> str:
    """Generate a unique ID for a question."""
    content = f"{question.get('company', '')}{question.get('question', '')[:50]}"
    return hashlib.md5(content.encode()).hexdigest()[:12]


def render_community_answers(question_id: str, question_text: str):
    """Render community answers section for a question."""
    
    # Load existing answers
    qa_data = load_question_answers(question_id)
    answers = qa_data.get("answers", [])
    
    st.markdown("### ðŸ‘¥ ç¤¾åŒºå›žç­”")
    
    if answers:
        # Sort by upvotes
        answers = sorted(answers, key=lambda x: x.get("upvotes", 0) - x.get("downvotes", 0), reverse=True)
        
        for ans in answers:
            with st.container():
                col1, col2 = st.columns([1, 9])
                
                with col1:
                    upvotes = ans.get("upvotes", 0)
                    downvotes = ans.get("downvotes", 0)
                    score = upvotes - downvotes
                    
                    if st.button("ðŸ‘", key=f"up_{question_id}_{ans['id']}"):
                        vote_answer(question_id, ans["id"], True)
                        st.rerun()
                    
                    st.markdown(f"**{score}**")
                    
                    if st.button("ðŸ‘Ž", key=f"down_{question_id}_{ans['id']}"):
                        vote_answer(question_id, ans["id"], False)
                        st.rerun()
                
                with col2:
                    author = ans.get("author", "åŒ¿å")
                    created_at = ans.get("created_at", "")[:10]
                    st.caption(f"ðŸ‘¤ {author} | ðŸ• {created_at}")
                    st.markdown(ans.get("content", ""))
                
                st.markdown("---")
    else:
        st.info("æš‚æ— ç¤¾åŒºå›žç­”ï¼Œæˆä¸ºç¬¬ä¸€ä¸ªå›žç­”è€…å§ï¼")
    
    # Add answer form
    st.markdown("### âœï¸ æˆ‘æ¥å›žç­”")
    
    with st.form(f"answer_form_{question_id}"):
        user_answer = st.text_area(
            "ä½ çš„å›žç­”",
            height=150,
            placeholder="åˆ†äº«ä½ çš„è§£é¢˜æ€è·¯ã€é¢è¯•ç»éªŒæˆ–è¡¥å……å†…å®¹...",
            key=f"answer_input_{question_id}"
        )
        
        col1, col2 = st.columns(2)
        with col1:
            author_name = st.text_input("ä½ çš„æ˜µç§°", value=st.session_state.get("username", ""), key=f"author_{question_id}")
        with col2:
            anonymous = st.checkbox("åŒ¿åæäº¤", key=f"anon_{question_id}")
        
        submitted = st.form_submit_button("ðŸ“ æäº¤å›žç­”", type="primary")
        
        if submitted and user_answer:
            answer = {
                "id": hashlib.md5(f"{user_answer}{datetime.now()}".encode()).hexdigest()[:12],
                "content": user_answer,
                "author": "åŒ¿åç”¨æˆ·" if anonymous else (author_name or "åŒ¿åç”¨æˆ·"),
                "created_at": datetime.now().isoformat(),
                "upvotes": 0,
                "downvotes": 0
            }
            save_question_answer(question_id, answer)
            st.success("å›žç­”æäº¤æˆåŠŸï¼æ„Ÿè°¢ä½ çš„è´¡çŒ® ðŸŽ‰")
            st.rerun()




def load_interview_questions() -> Dict:
    """Load interview questions from JSON file."""
    questions_file = Path(__file__).parent.parent.parent / "data" / "interview_questions.json"
    
    if questions_file.exists():
        with open(questions_file, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"questions": [], "metadata": {}, "categories": {}}


def render_interview_questions():
    """Render the interview questions browser page."""
    
    # Custom CSS
    st.markdown("""
    <style>
    .question-card {
        background: linear-gradient(135deg, #1e293b 0%, #334155 100%);
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        border-left: 4px solid #3b82f6;
    }
    .frequency-badge {
        display: inline-block;
        padding: 2px 8px;
        border-radius: 12px;
        font-size: 0.75rem;
        font-weight: 600;
    }
    .freq-5 { background: #dc2626; color: white; }
    .freq-4 { background: #f59e0b; color: black; }
    .freq-3 { background: #10b981; color: white; }
    .stats-card {
        background: linear-gradient(135deg, #312e81 0%, #4c1d95 100%);
        border-radius: 16px;
        padding: 1.5rem;
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("## ðŸ“š MLE é¢è¯•é¢˜åº“")
    st.markdown("*ä¸“ä¸º Machine Learning Engineer æ‰“é€ çš„é«˜è´¨é‡é¢è¯•é¢˜åº“*")
    
    # Load data
    data = load_interview_questions()
    questions = data.get("questions", [])
    metadata = data.get("metadata", {})
    categories = data.get("categories", {})
    
    if not questions:
        st.warning("é¢˜åº“æš‚æ— æ•°æ®")
        return
    
    # ============ Stats Dashboard ============
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ðŸ“Š é¢˜ç›®æ€»æ•°", len(questions))
    with col2:
        hard_count = len([q for q in questions if q.get("difficulty") == "hard"])
        st.metric("ðŸ”´ é«˜éš¾åº¦é¢˜", hard_count)
    with col3:
        high_freq = len([q for q in questions if q.get("frequency", 0) >= 4])
        st.metric("ðŸ”¥ é«˜é¢‘é¢˜", high_freq)
    with col4:
        companies = len(set(q.get("company", "") for q in questions))
        st.metric("ðŸ¢ è¦†ç›–å…¬å¸", companies)
    
    st.markdown(f"*ðŸ• æ›´æ–°æ—¶é—´: {metadata.get('last_updated', 'N/A')}*")
    st.markdown("---")
    
    # ============ Filters ============
    st.markdown("### ðŸ” æ™ºèƒ½ç­›é€‰")
    
    col1, col2, col3 = st.columns(3)
    
    # Get unique values
    companies_list = sorted(set(q.get("company", "") for q in questions))
    domains_list = categories.get("domains", [])
    rounds_list = categories.get("rounds", [])
    levels_list = categories.get("levels", [])
    
    with col1:
        selected_company = st.selectbox(
            "ðŸ¢ ç›®æ ‡å…¬å¸",
            ["å…¨éƒ¨"] + companies_list,
            key="filter_company_v2"
        )
        
        selected_domain = st.selectbox(
            "ðŸ§  çŸ¥è¯†é¢†åŸŸ",
            ["å…¨éƒ¨"] + domains_list,
            format_func=lambda x: {
                "å…¨éƒ¨": "å…¨éƒ¨é¢†åŸŸ",
                "fundamentals": "ðŸ“— ML åŸºç¡€",
                "deep_learning": "ðŸ”® æ·±åº¦å­¦ä¹ ",
                "nlp": "ðŸ“ NLP",
                "cv": "ðŸ‘ï¸ è®¡ç®—æœºè§†è§‰",
                "recsys": "ðŸŽ¯ æŽ¨èç³»ç»Ÿ",
                "ranking": "ðŸ“ˆ æœç´¢æŽ’åº",
                "llm": "ðŸ¤– å¤§è¯­è¨€æ¨¡åž‹",
                "mlops": "âš™ï¸ MLOps",
                "experimentation": "ðŸ§ª å®žéªŒå¹³å°"
            }.get(x, x),
            key="filter_domain"
        )
    
    with col2:
        selected_round = st.selectbox(
            "ðŸ“‹ é¢è¯•è½®æ¬¡",
            ["å…¨éƒ¨"] + rounds_list,
            format_func=lambda x: {
                "å…¨éƒ¨": "å…¨éƒ¨è½®æ¬¡",
                "phone_screen": "ðŸ“ž Phone Screen",
                "coding": "ðŸ’» Coding",
                "ml_coding": "ðŸ ML Coding",
                "ml_theory": "ðŸ“– ML ç†è®º",
                "ml_system_design": "ðŸ—ï¸ ML ç³»ç»Ÿè®¾è®¡",
                "system_design": "ðŸŒ é€šç”¨ç³»ç»Ÿè®¾è®¡",
                "behavioral": "ðŸ—£ï¸ è¡Œä¸ºé¢è¯•"
            }.get(x, x),
            key="filter_round_v2"
        )
        
        selected_level = st.selectbox(
            "ðŸ“Š ç›®æ ‡çº§åˆ«",
            ["å…¨éƒ¨"] + levels_list,
            key="filter_level"
        )
    
    with col3:
        selected_difficulty = st.selectbox(
            "â­ éš¾åº¦",
            ["å…¨éƒ¨", "easy", "medium", "hard"],
            format_func=lambda x: {
                "å…¨éƒ¨": "å…¨éƒ¨éš¾åº¦",
                "easy": "ðŸŸ¢ Easy (å…¥é—¨)",
                "medium": "ðŸŸ¡ Medium (æ ‡å‡†)",
                "hard": "ðŸ”´ Hard (æŒ‘æˆ˜)"
            }.get(x, x),
            key="filter_difficulty_v2"
        )
        
        min_frequency = st.slider(
            "ðŸ”¥ æœ€ä½Žé«˜é¢‘åº¦",
            min_value=1, max_value=5, value=1,
            help="ç­›é€‰é«˜é¢‘é¢˜ç›® (5=å¿…è€ƒ)"
        )
    
    # Apply filters
    filtered = questions
    if selected_company != "å…¨éƒ¨":
        filtered = [q for q in filtered if q.get("company") == selected_company]
    if selected_domain != "å…¨éƒ¨":
        filtered = [q for q in filtered if q.get("domain") == selected_domain]
    if selected_round != "å…¨éƒ¨":
        filtered = [q for q in filtered if q.get("round") == selected_round]
    if selected_level != "å…¨éƒ¨":
        filtered = [q for q in filtered if q.get("level") == selected_level]
    if selected_difficulty != "å…¨éƒ¨":
        filtered = [q for q in filtered if q.get("difficulty") == selected_difficulty]
    filtered = [q for q in filtered if q.get("frequency", 0) >= min_frequency]
    
    st.markdown(f"**ç­›é€‰ç»“æžœ: {len(filtered)} é“é¢˜ç›®**")
    st.markdown("---")
    
    # ============ Questions List ============
    if not filtered:
        st.info("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„é¢˜ç›®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
        return
    
    # Sort by frequency then importance
    filtered = sorted(filtered, key=lambda x: (x.get("frequency", 0), x.get("importance", 0)), reverse=True)
    
    for i, q in enumerate(filtered):
        # Question header with badges
        freq = q.get("frequency", 0)
        freq_badge = "ðŸ”¥" * min(freq, 5)
        
        difficulty_colors = {"easy": "ðŸŸ¢", "medium": "ðŸŸ¡", "hard": "ðŸ”´"}
        diff_icon = difficulty_colors.get(q.get("difficulty", ""), "âšª")
        
        domain_icons = {
            "fundamentals": "ðŸ“—", "deep_learning": "ðŸ”®", "nlp": "ðŸ“",
            "cv": "ðŸ‘ï¸", "recsys": "ðŸŽ¯", "ranking": "ðŸ“ˆ",
            "llm": "ðŸ¤–", "mlops": "âš™ï¸", "experimentation": "ðŸ§ª"
        }
        domain_icon = domain_icons.get(q.get("domain", ""), "ðŸ“š")
        
        with st.expander(
            f"{freq_badge} {diff_icon} **{q.get('question', '')[:70]}{'...' if len(q.get('question', '')) > 70 else ''}**",
            expanded=i < 2
        ):
            # Meta info row
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.markdown(f"ðŸ¢ **{q.get('company', '')}**")
            with col2:
                st.markdown(f"ðŸ“Š **{q.get('level', '')}**")
            with col3:
                st.markdown(f"{domain_icon} **{q.get('domain', '').replace('_', ' ').title()}**")
            with col4:
                st.markdown(f"ðŸ”¥ é«˜é¢‘åº¦: **{freq}/5**")
            
            st.markdown("---")
            
            # Full question
            st.markdown("### ðŸ“ é¢˜ç›®")
            st.markdown(q.get("question", ""))
            
            # Round type
            round_names = {
                "phone_screen": "ðŸ“ž Phone Screen",
                "coding": "ðŸ’» Coding",
                "ml_coding": "ðŸ ML Coding å®žçŽ°",
                "ml_theory": "ðŸ“– ML ç†è®ºæ·±åº¦",
                "ml_system_design": "ðŸ—ï¸ ML ç³»ç»Ÿè®¾è®¡",
                "system_design": "ðŸŒ é€šç”¨ç³»ç»Ÿè®¾è®¡",
                "behavioral": "ðŸ—£ï¸ è¡Œä¸ºé¢è¯•"
            }
            st.markdown(f"**è½®æ¬¡**: {round_names.get(q.get('round', ''), q.get('round', ''))}")
            
            # Answer
            st.markdown("### ðŸ’¡ å‚è€ƒç­”æ¡ˆ")
            answer = q.get("answer", "")
            if answer.startswith("```"):
                st.code(answer.replace("```python", "").replace("```", ""), language="python")
            else:
                st.markdown(answer)
            
            # Follow-ups
            if q.get("follow_ups"):
                st.markdown("### ðŸ”„ å¸¸è§è¿½é—®")
                for fu in q.get("follow_ups", []):
                    st.markdown(f"- {fu}")
            
            # Common mistakes
            if q.get("common_mistakes"):
                st.markdown("### âš ï¸ å¸¸è§é”™è¯¯")
                for cm in q.get("common_mistakes", []):
                    st.error(f"âŒ {cm}")
            
            # Tags
            if q.get("tags"):
                tags_str = " ".join([f"`{tag}`" for tag in q.get("tags", [])])
                st.markdown(f"**ðŸ·ï¸ æ ‡ç­¾**: {tags_str}")
            
            # ========== Community Answers Section ==========
            st.markdown("---")
            question_id = get_question_id(q)
            qa_data = load_question_answers(question_id)
            num_answers = len(qa_data.get("answers", []))
            
            with st.expander(f"ðŸ’¬ ç¤¾åŒºå›žç­” ({num_answers})", expanded=False):
                render_community_answers(question_id, q.get("question", ""))
    
    st.markdown("---")
    
    # ============ Learning Path Suggestion ============
    st.markdown("### ðŸ“š æŽ¨èå­¦ä¹ è·¯å¾„")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **ðŸŽ¯ MLE é¢è¯•å‡†å¤‡é¡ºåº**
        
        1. **ML åŸºç¡€** (1-2 å‘¨)
           - Bias-Variance, Regularization
           - Cross-validation, Metrics
        
        2. **æ·±åº¦å­¦ä¹ ** (1-2 å‘¨)
           - Transformer, Attention
           - Normalization, Optimization
        
        3. **ML ç³»ç»Ÿè®¾è®¡** (2-3 å‘¨)
           - æŽ¨èç³»ç»Ÿ, æŽ’åºç³»ç»Ÿ
           - å¹¿å‘Šç‚¹å‡»é¢„ä¼°
        
        4. **LLM ä¸“é¡¹** (1 å‘¨)
           - RAG, Fine-tuning
           - Prompt Engineering
        """)
    
    with col2:
        st.markdown("""
        **ðŸ¢ æŒ‰å…¬å¸å‡†å¤‡ç­–ç•¥**
        
        - **Google**: é‡è§† ML ç†è®ºæ·±åº¦ + Coding
        - **Meta**: å¼ºè°ƒç³»ç»Ÿè®¾è®¡ + å®žéªŒèƒ½åŠ›
        - **Amazon**: LP è¡Œä¸ºé¢è¯• + ç³»ç»Ÿè®¾è®¡
        - **ByteDance**: æŽ¨è/æŽ’åºç³»ç»Ÿ + Coding
        - **OpenAI**: LLM ç†è®º + ç³»ç»Ÿè®¾è®¡
        """)
